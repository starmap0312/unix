# hadoop fs <args>
  1) list a folder (option -ls -R: list recursively)
     ex. hadoop fs -ls /path/to/hadoop/folder
         hls /path/to/hadoop/folder
     ex. hadoop fs -ls -R /path/to/hadoop/folder
         hls /path/to/hadoop/folder
  2) download a hadoop folder
     ex. hadoop fs -get /path/to/folder
  3) upload a local folder / file to hadoop
     ex. hadoop fs -put /path/to/local/folder/ /path/to/hadoop/folder
         hadoop fs -put -f /path/to/local/folder/filename /path/to/hadoop/folder/filename
           -f: force, to overwirte
  4) cat a hadoop file
     ex. hadoop fs -cat /path/to/filename
  5) count the number of directories, files and bytes under the path
     ex. hadoop fs -count -q /path/to/hadoop/folder
         hdfs dfs -count -q hdfs://nn1.example.com/file1
  6) make a folder
     hadoop fs -mkdir [-p] /path/to/folder
  7) move a folder
     hadoop fs -mv /user/hadoop/folder1 /user/hadoop/folder2
  8) remove a folder recursively
     hadoop fs -rm -r /user/hadoop/folder
  9) hadoop dfs -count <paths>
     ex. hdfs dfs -count hdfs://nn1.example.com/file1 hdfs://nn2.example.com/file2
 10) outputs the file in text format (allowed formats: zip and TextRecordInputStream)
     ex. hadoop fs -text /path/to/filename.zip
         hadoop fs -text /path/to/filename.tgz

# hadoop fsck: runs a HDFS filesystem checking utility
  hadoop fsck <path>: start checking from this path
  ex. hadoop fsck /

# hadoop distcp: migrate data between two clusters
  hadoop distcp hftp://cdh3-namenode:50070/ hdfs://cdh4-nameservice/
